name: Run Job Scraper Hourly

on:
  schedule:
    - cron: '0 * * * *' 
  workflow_dispatch: # Дозволяє вручну запускати робочий процес

jobs:
  run_scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.11'

    - name: Restore cached CSV files
      uses: actions/cache@v3
      id: csv-cache
      with:
        path: ./csv_files
        key: csv-cache-${{ runner.os }}-${{ hashFiles('**/csv_files/*.csv') }}
        restore-keys: |
          csv-cache-${{ runner.os }}

    - name: Ensure CSV directory exists
      run: mkdir -p ./csv_files

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run job scraper
      env:
        TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
        NO_EXP_TELEGRAM_TOKEN: ${{ secrets.NO_EXP_TELEGRAM_TOKEN }}
        CHAT_ID: ${{ secrets.CHAT_ID }}
        NO_EXP_CHAT_ID: ${{ secrets.NO_EXP_CHAT_ID }}
      run: python main.py

    - name: Debug CSV files
      run: |
        echo "Debugging CSV files before updating cache..."
        ls -l ./csv_files
        cat ./csv_files/*.csv || echo "No CSV files found"

    - name: Update cache with new CSV files
      if: always()
      uses: actions/cache@v3
      with:
        path: ./csv_files
        key: csv-cache-${{ runner.os }}-${{ github.run_id }}
